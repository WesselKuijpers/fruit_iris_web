{
    "en": {
        "translations": {
            "page.index.upload.caption": "Tap to upload photo",
            "page.index.result.try-again.button": "Try Again!",
            "page.index.result.survey.title": "Help us out?",
            "page.index.result.survey.dropdown.default": "Did it work?",
            "page.index.result.survey.dropdown.positive": "yes",
            "page.index.result.survey.dropdown.negative": "no",
            "page.index.result.survey.answered.thank-you": "Thank you!",
            "page.index.result.survey.answered.dropdown.default": "Then what is it?",
            "base.navbar.link.home": "home",
            "base.navbar.link.insight": "insights",
            "base.navbar.link.rate": "rate",
            "insight.jumbotron.title": "Argos IRIS Insights",
            "insight.jumbotron.lead": "This page contains all the information about the inner workings of Argos IRIS, as well as metrics calculated on the model. <br> The data on this page is continuously being updated with the latest metrics, because the model is constantly adapting to new data.",
            "insight.accuracy-and-loss.intro.title": "Accuracy and Loss",
            "insight.accuracy-and-loss.intro.lead": "Below you will find the metrics for the accuracy and loss of the current model during the training process. <br> The lines labled 'training accuracy' and 'training loss' contain the metrict during the actual process with data that the model has 'seen' before. <br> The lines labled 'validation accuracy' and 'validation loss' show how the model preformed in predicting data that was never seen before. <br> Ideally, the validation line should closely follow the training line.",
            "insight.accuracy-and-loss.accuracy.title": "Accuracy",
            "insight.accuracy-and-loss.accuracy.subtitle": "Higher is better, in percentage",
            "insight.accuracy-and-loss.accuracy.explanation": "The accuracy of a model is usually determined after the model parameters are learned and fixed and no learning is taking place. Then the test samples are fed to the model and the number of mistakes (zero-one loss) the model makes are recorded, after comparison to the true targets. Then the percentage of misclassification is calculated. <br> For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is 95.2%.",
            "insight.accuracy-and-loss.loss.title": "Loss",
            "insight.accuracy-and-loss.loss.subtitle": "Lower is better",
            "insight.accuracy-and-loss.loss.explanation": "Loss value implies how well or poorly a certain model behaves after each iteration of optimization. Ideally, one would expect the reduction of loss after each, or several, iteration(s). <br> Loss is often used in the training process to find the 'best' parameter values for your model (e.g. weights in neural network). It is what you try to optimize in the training by updating weights.",
            "insight.classification-report.intro.title": "Classification Report",
            "insight.classification-report.intro.lead": "When a training process is finished a report is generated to validate the precision of the model. <br> This report is generated by running 10402 images the model has never seen before by it. The model then gives it's prediction, the outcome of this, matched with the actual label of the respective images, is fed into several mathematical functions returning the metrics below.",
            "insight.classification-report.support.title": "Support",
            "insight.classification-report.support.subtitle": "How many images exist inside each category of the test set",
            "insight.classification-report.precision.title": "Per class precision",
            "insight.classification-report.precision.subtitle": "in percentages",
            "insight.classification-report.precision.explanation": "Precision – Accuracy of positive predictions. <br> The precision is being calculated with the following formula:",
            "insight.classification-report.precision.formula":  "Precision = True Positives / (True Positives + False Positives)",
            "insight.classification-report.recall.title": "Per class recall score",
            "insight.classification-report.recall.subtitle": "in percentages",
            "insight.classification-report.recall.explanation": "Recall (sensitivity or true positive rate) – Fraction of positives That were correctly identified. <br> The Recall Score is being calculated with the following formula:",
            "insight.classification-report.recall.formula": "Precision = True Positives / (True Positives + False Negatives)",
            "insight.classification-report.f1.title": "Per class F1 score",
            "insight.classification-report.f1.subtitle": "in percentages",
            "insight.classification-report.f1.explanation": "F1 Score (F-Score or F-Measure) – A metric for comparing two classifiers. F1 Score takes into account precision and the recall. It is created by finding the the harmonic mean of precision and recall. <br> The F1 Score is being calculated with the following formula:",
            "insight.classification-report.f1.formula": "F1 = 2 x (precision x recall)/(precision + recall)",
            "insight.confusion-matrix.intro.title": "Confusion Matrix",
            "insight.confusion-matrix.intro.lead": "When a training process is finished a confusion matrix is generated to give a better insight in the precision of the model. <br> The confusion matrix shows how often certain classes are predicted and how images are misclassified. Ideally a digagonal 'line' should be discernable in the confusion matrix.",
            "insight.confusion-matrix.table.title": "Confusion Matrix",
            "insight.confusion-matrix.table.subtitle": "A matrix, labeled by class",
            "insight.current-training.title": "Current Training",
            "insight.current-training.lead": "The model that we use to make predictions is constantly improving. The metrics below give insight into the training that is currently being conducted.",
            "insight.current-training.progress.title": "Progress:",
            "insight.current-training.metrics.title": "Metrics:",
            "insight.current-training.metrics.accuracy": "Accuracy",
            "insight.current-training.metrics.validation-accuracy": "Validation Accuracy",
            "insight.current-training.metrics.loss": "Loss",
            "insight.current-training.metrics.validation-loss": "Validation Loss",
            "insight.current-situation.metrics.accuracy.popover": "The accuracy of a model is usually determined after the model parameters are learned and fixed and no learning is taking place. Then the test samples are fed to the model and the number of mistakes (zero-one loss) the model makes are recorded, after comparison to the true targets. Then the percentage of misclassification is calculated. <br> For example, if the number of test samples is 1000 and model classifies 952 of those correctly, then the model's accuracy is 95.2%. <br> Higher is better.",
            "insight.current-situation.metrics.validation-accuracy.popover": "The validation accuracy metric is calculated in the same way the accuracy is. <br> The difference is that the validation accuracy is calculated on data that the model has never 'seen' before. <br> For a perfect model this should be the same as the accuracy but in practice this rarely happens",
            "insight.current-situation.metrics.loss.popover": "Loss value implies how well or poorly a certain model behaves after each iteration of optimization. Ideally, one would expect the reduction of loss after each, or several, iteration(s). Loss is often used in the training process to find the 'best' parameter values for your model (e.g. weights in neural network). It is what you try to optimize in the training by updating weights.<br> Lower is better.",
            "insight.current-situation.metrics.validation-loss.popover": "The validation loss is calculated the same way the loss is calculated, it is different because the validation is calculated on data that the model has never seen before. In the perfect situation the validation loss should be the same as the loss, but this rarely happens",
            "insight.training-explanation.title": "How does Argos IRIS work",
            "insight.training-explanation.content": "When a prediction is made using Argos IRIS and the survey is subsequently answered, new data is added to our dataset. This data in itself is not improving the model yet. The model (needed to make predictions) needs to update itself with the new knowledge. To do this a so-called training process is started.  <br> This process runs continuously, and asyncronously with our prediction service so that the user experience is not hindered in any way. <br><br> The model that we use is a deeply trained MobileNet model. This model is made out of several layers with their own responsibility. <br> When a prediction is made a single image is passed through these layers and a so-called 'feature map' is created containing indexes of similarity with known patterns. This 'feature map' will be compared with known classes and based on that a prediction will be given. <br><br> During a training process a stream of images is fed into the model, again, the model makes a prediction per image. Now the correct label is also given to the model. <br> The model can now update it's 'weights' so that the patterns that were discerned in the image can be used to recognise images of the same class in the future. This process continues, and so the model 'learns' new patterns. <br> This process repeats for each image in the dataset, and for 100 iterations (or Epochs). After this process is completed the model will be loaded into the prediction service, some metrics will be generated and the training process will restart. "
        },
        "fullname": "English"
    },
    "nl": {
        "translations": {
            "page.index.upload.caption": "Tik om foto te uploaden",
            "page.index.result.try-again.button": "Opnieuw!",
            "page.index.result.survey.title": "Handje helpen?",
            "page.index.result.survey.dropdown.default": "Klopt de voorspelling?",
            "page.index.result.survey.dropdown.positive": "ja",
            "page.index.result.survey.dropdown.negative": "nee",
            "page.index.result.survey.answered.thank-you": "Bedankt!",
            "page.index.result.survey.answered.dropdown.default": "Wat is het dan?",
            "base.navbar.link.home": "home",
            "base.navbar.link.insight": "statistieken",
            "base.navbar.link.rate": "beoordelen",
            "insight.jumbotron.title": "Argos IRIS statistieken",
            "insight.jumbotron.lead": "Deze pagina bevat informatie over de werking van Argos IRIS, evenals statistieken berekend op basis van het gebruikte model. <br> De data op deze pagina wordt constant geüpdate omdat het model zich constant aanpast aan nieuwe data.",
            "insight.accuracy-and-loss.intro.title": "'Accuracy' en 'Loss'",
            "insight.accuracy-and-loss.intro.lead": "Hieronder staan statisitieken over de 'accuracy' en 'loss' van het huidige model tijdens de laatste trainingsperiode. <br> De lijnen met label 'training accuracy' en 'training loss' bevatten de gevens tijdens het daadwerkelijke proces met data die het model al eerder heeft 'gezien'. <br> De lijnen met labels 'validation accuracy' en 'validation loss' laten zien hoe goed het model presteert tijdens het voorspellen van data die het nog niet eerder heeft 'gezien'. <br> In de ideale situatie volgt de validatielijn de trainingslijn op de voet.",
            "insight.accuracy-and-loss.accuracy.title": "Accuracy",
            "insight.accuracy-and-loss.accuracy.subtitle": "Hoe hoger, hoe beter. Een percentage",
            "insight.accuracy-and-loss.accuracy.explanation": "De accuracy van een model wordt over het algemeen vastgesteld nadat de parameters van het model vastgelegd en geleerd zij en er niet meer geleerd wordt. De test data wordt aan het model gegeven en het aantal fouten (zero-one loss) die het model maakt worden opgeslagen, nadat de vergelijking met de 'echte' labels is gemaakt. Daarna wordt het percentage van misvattingen berekend. <br> Een voorbeeld: als het aantal testafbeeldingen 1000 is en het model classificeerd 952 van deze correct, dan is de 'accuracy' van het model 95.2%.",
            "insight.accuracy-and-loss.loss.title": "Loss",
            "insight.accuracy-and-loss.loss.subtitle": "Hoe lager, hoe beter",
            "insight.accuracy-and-loss.loss.explanation": "De 'loss'- waarde impliceert hoe 'goed' of 'slecht' het model presteert na elke iteratie van optimalisatie. Idealiter is te verwachten dat deze waarde na elke iteratie afneemt. <br> Loss wordt gebruikt om de 'beste' parameters voor modeltraining the vinden (bijvoorbeeld 'weights' in neuraal netwerk). Dit optimalizeren gebeurt door de 'weights' te updaten.",
            "insight.classification-report.intro.title": "Classificatie rapport",
            "insight.classification-report.intro.lead": "Wanneer een trainingsprocess wort afgesloten wordt er automatisch een classificatieraport gegenereerd om de prestatie van het model te kunnen meten. <br> Dit rapport wordt gegenereerd door 10402 afbeeldingen, die het model nog nooit gezien heeft, aan het model te laten zien. Het model geeft zijn voorspelling, de uitkomst hiervan, gepaard met het 'echte' bijbehpordende label, wordt gebruikt in verschillende wiskundige functies. Dit levert de onderstaande statistieken op.",
            "insight.classification-report.support.title": "Support",
            "insight.classification-report.support.subtitle": "Hoeveel afbeeldingen bevat elke categorie van de testdataset.",
            "insight.classification-report.precision.title": "Precisie per klasse",
            "insight.classification-report.precision.subtitle": "Een percentage",
            "insight.classification-report.precision.explanation": "Precisie – nauwkeurigheid van positieve voorspellingen. <br> De precisie wordt berekend aan de hand van de volgende formule:",
            "insight.classification-report.precision.formula":  "Precisie = terechte positieven / (terechte positieven + onterechte positieven)",
            "insight.classification-report.recall.title": "'Recall' -score per klasse",
            "insight.classification-report.recall.subtitle": "Een percentage",
            "insight.classification-report.recall.explanation": "Recall (gevoeligheid of mate van terechte positieven) – Fractie van de positieven de juist geïdentificeerd zijn. <br> De 'recall' score wordt met de volgende formule berekend:",
            "insight.classification-report.recall.formula": "Recall = terechte positieven / (terechte positieven + onterechte negatieven)",
            "insight.classification-report.f1.title": "F1-score per klasse",
            "insight.classification-report.f1.subtitle": "Een percentage",
            "insight.classification-report.f1.explanation": "F1 Score – Een methode om twee waarden te vergelijken. F1-Score neemt zowel de precision als de 'recall' in acht. Ze wordt gevormd door de harmonie in de precisie en 'recall' te vinden. <br> De F1-score wordt volgens de volgende formule berekend:",
            "insight.classification-report.f1.formula": "F1 = 2 x (precisie x recall)/(precisie + recall)",
            "insight.confusion-matrix.intro.title": "Confusion Matrix",
            "insight.confusion-matrix.intro.lead": "Wanneer een trainprocess voltooid is wordt er een confusion matrix gegenereed, deze geeft inzicht in de voorspellingen die door het model gemaakt worden. Idealiter zou er een diagonale 'lijn' in de matrix zichtbaar moeten zijn.",
            "insight.confusion-matrix.table.title": "Confusion Matrix",
            "insight.confusion-matrix.table.subtitle": "Een matrix, per klasse",
            "insight.current-training.title": "Huidige Training",
            "insight.current-training.lead": "Het model dat gebruikt wordt om voorspellingen te maken wordt constant aangepast aan nieuwe data. The statistieken hieronder geven inzicht in het huidige trainingsproces.",
            "insight.current-training.progress.title": "Voortgang:",
            "insight.current-training.metrics.title": "Statistieken:",
            "insight.current-training.metrics.accuracy": "Accuracy",
            "insight.current-training.metrics.validation-accuracy": "Validation Accuracy",
            "insight.current-training.metrics.loss": "Loss",
            "insight.current-training.metrics.validation-loss": "Validation Loss",
            "insight.current-situation.metrics.accuracy.popover": "De accuracy van een model wordt over het algemeen vastgesteld nadat de parameters van het model vastgelegd en geleerd zij en er niet meer geleerd wordt. De test data wordt aan het model gegeven en het aantal fouten (zero-one loss) die het model maakt worden opgeslagen, nadat de vergelijking met de 'echte' labels is gemaakt. Daarna wordt het percentage van misvattingen berekend. <br> Een voorbeeld: als het aantal testafbeeldingen 1000 is en het model classificeerd 952 van deze correct, dan is de 'accuracy' van het model 95.2%. <br> Hoe Hoger, hoe beter.",
            "insight.current-situation.metrics.validation-accuracy.popover": "De 'validation accuracy' wordt op eenzelfde manier als de 'accuracy' berkend. <br> Het verschil is dat de 'validation accuracy' berkend wordt op data die het model nog nooit gezien heeft. <br> Als het model perfect is moet deze waarde hetzelfde zijn als de 'accuracy'. Dit gebeurt zelden",
            "insight.current-situation.metrics.loss.popover": "De 'loss'- waarde impliceert hoe 'goed' of 'slecht' het model presteert na elke iteratie van optimalisatie. Idealiter is te verwachten dat deze waarde na elke iteratie afneemt. <br> Loss wordt gebruikt om de 'beste' parameters voor modeltraining the vinden (bijvoorbeeld 'weights' in neuraal netwerk). Dit optimalizeren gebeurt door de 'weights' te updaten.<br> Hoe lager, hoe beter.",
            "insight.current-situation.metrics.validation-loss.popover": "De 'validation loss' wordt op dezelfde manier berekend als de 'loss' -waarde, het verschil is dat deze waarde wordt berekend op data die het model nog niet eerder heeft 'gezien'. In de prefecte situatie is deze waarde gelijk aan de 'loss' -waarde, dit gebeurt zeer zelden",
            "insight.training-explanation.title": "Hoe werkt Argos IRIS",
            "insight.training-explanation.content": "Wanneer er een voorspelling gemaakt wordt met Argos IRIS en de enquete wordt beantwoord wordt er nieuwe data aan onze dataset toegevoegd. Deze nieuwe data op zich verbeterd het model nog niet. Het model (hiermee worden de voorspellingen gemaakt) moet geupdate worden met de nieuwe data. Om deze reden wordt een nieuw train-proces gestart. <br> Dit proces loopt continue, en asynchroon met onze voorspelservice zodat het gebruik van Argos IRIS niet wordt verhinderd. <br><br>Het model waar wij gebruik van maken is een diep getraind MobileNet model. Dit model bestaat uit verschillende lagen, elk met zijn eigen verantwoordelijkheid. <br> Wanneer er een voorspelling wordt gemaakt wordt er aan de hand van bekende patronen een zogenaamde 'feature map' gercreeerd met indexen van overeenkomst met bekende klassen. deze 'feature map' wordt vergeleken met bekende klassen om zo een voorspelling te kunnen doen. <br><br> Gedurende een training-proces wordt er een stroom van afbeeldingen aan het model gegeven, wederom doet het model per afbeelding een voorspelling. In deze situatie wordt het correcte label ook met de afbeelding meegegeven. <br> zo kan het model zijn 'weights' updaten zodat patronen die uit de afbeelding gehaald zijn gebruikt kunnen worden om afbeeldingen van dezelfde klasse te herkennen in de toekomst. Dit proces loopt door en zo leert het model nieuwe patronen. <br> Dit proces loopt door voor elke afbeelding in de dataset, en voor 100 iteraties (of Epochs). Wanneer dit process klaar is wordt het nieuwe model ingeladen, een paar statistieken worden gegenereerd en het train-proces wordt opnieuw gestart. "
        },
        "fullname": "Nederlands"
    }
}